name: RAG System Tests

on:
  push:
    branches: [feature/*]
    paths:
      - "rag/**"
      - ".github/workflows/rag-test.yml"
  pull_request:
    branches: [feature/*]
    paths:
      - "rag/**"
      - ".github/workflows/rag-test.yml"

jobs:
  test-rag:
    name: Run RAG System Tests
    runs-on: ubuntu-latest

    # Add Neo4j service container
    services:
      neo4j:
        image: neo4j:5.15
        env:
          NEO4J_AUTH: none
          NEO4J_PLUGINS: '["graph-data-science"]'
          NEO4J_dbms_memory_pagecache_size: 1G
          NEO4J_dbms_memory_heap_initial__size: 1G
          NEO4J_dbms_memory_heap_max__size: 1G
        ports:
          - 7687:7687
          - 7474:7474
        options: >-
          --health-cmd "cypher-shell -u neo4j -p neo4j 'RETURN 1' || exit 1"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 10
          --health-start-period 30s

    defaults:
      run:
        working-directory: ./

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"
          cache: "pip"
          cache-dependency-path: "**/requirements*.txt"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          # Install test dependencies from requirements-test.txt
          # This file contains OpenAI 1.x and excludes helicone
          pip install -r rag/requirements-test.txt

      # Cache NLTK data to speed up subsequent runs
      - name: Cache NLTK data
        uses: actions/cache@v3
        with:
          path: ~/nltk_data
          key: nltk-data-${{ runner.os }}-v1
          restore-keys: |
            nltk-data-${{ runner.os }}-

      - name: Download NLTK data
        run: |
          python -c "
          import nltk
          import os
          nltk.data.path.append(os.path.expanduser('~/nltk_data'))
          print('Downloading NLTK data...')
          try:
              nltk.download('punkt', quiet=True)
              print('Downloaded punkt')
          except Exception as e:
              print(f'Error downloading punkt: {e}')
          try:
              nltk.download('punkt_tab', quiet=True)
              print('Downloaded punkt_tab')
          except Exception as e:
              print(f'Error downloading punkt_tab: {e}')
          try:
              nltk.download('stopwords', quiet=True)
              print('Downloaded stopwords')
          except Exception as e:
              print(f'Error downloading stopwords: {e}')
          try:
              nltk.download('vader_lexicon', quiet=True)
              print('Downloaded vader_lexicon')
          except Exception as e:
              print(f'Error downloading vader_lexicon: {e}')
          print('NLTK data download completed')
          "

      # Cache Spacy models to speed up subsequent runs
      - name: Cache Spacy models
        uses: actions/cache@v3
        with:
          path: ~/.local/lib/python3.10/site-packages/en_core_web_sm
          key: spacy-en-model-${{ runner.os }}-v1
          restore-keys: |
            spacy-en-model-${{ runner.os }}-

      - name: Download Spacy models
        run: |
          echo "Downloading English Spacy model..."
          python -m spacy download en_core_web_sm || echo "English model download failed"
          echo "Downloading Spanish Spacy model (optional)..."
          python -m spacy download es_core_news_sm || echo "Spanish model download failed, tests should handle this gracefully"
          echo "Spacy models download completed"

      - name: Verify installations
        run: |
          echo "Verifying NLTK data..."
          python -c "
          import nltk
          try:
              nltk.data.find('tokenizers/punkt_tab')
              print('✓ punkt_tab found')
          except LookupError:
              print('✗ punkt_tab not found')
          try:
              nltk.data.find('tokenizers/punkt')
              print('✓ punkt found')
          except LookupError:
              print('✗ punkt not found')
          "
          echo "Verifying Spacy models..."
          python -c "
          import spacy
          try:
              nlp = spacy.load('en_core_web_sm')
              print('✓ en_core_web_sm loaded')
          except OSError:
              print('✗ en_core_web_sm not available')
          try:
              nlp = spacy.load('es_core_news_sm')
              print('✓ es_core_news_sm loaded')
          except OSError:
              print('✗ es_core_news_sm not available (fallback will be used)')
          "

      - name: Show openai version
        run: pip show openai

      # Wait for Neo4j to be ready
      - name: Wait for Neo4j
        run: |
          timeout 60 bash -c 'until nc -z localhost 7687; do sleep 2; done'
          echo "Neo4j is ready"

      - name: Run pytest
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          HELICONE_API_KEY: ${{ secrets.HELICONE_API_KEY }}
          # Neo4j environment variables
          NEO4J_URI: bolt://localhost:7687
          NEO4J_USERNAME: neo4j
          NEO4J_PASSWORD: ""
        run: |
          pytest rag/tests/ -v --tb=short

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: rag-test-results
          path: |
            rag/tests/reports/
            rag/tests/.coverage
          retention-days: 5
